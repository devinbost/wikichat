{"id":"453e2dc9-1cf0-4303-9080-3bdb83445fc7","data":{"nodes":[{"id":"ChatInput-qBbK8","type":"genericNode","position":{"x":68,"y":695.5680787446313},"data":{"description":"Get chat inputs from the Playground.","display_name":"Chat Input","id":"ChatInput-qBbK8","node":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Get chat inputs from the Playground.","display_name":"Chat Input","documentation":"","edited":false,"field_order":["input_value","store_message","sender","sender_name","session_id","files"],"frozen":false,"icon":"ChatInput","output_types":[],"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"pinned":false,"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"files":{"advanced":true,"display_name":"Files","dynamic":false,"fileTypes":["txt","md","mdx","csv","json","yaml","yml","xml","html","htm","pdf","docx","py","sh","sql","js","ts","tsx","jpg","jpeg","png","bmp","image"],"file_path":"","info":"Files to be sent with the message.","list":true,"name":"files","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"file","value":""},"input_value":{"advanced":false,"display_name":"Text","dynamic":false,"info":"Message to be passed as input.","input_types":["Message"],"list":false,"load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"{\"user_id\":\"8888888888\", \"user_question\":\"What's a summary of events?\"}"},"sender":{"advanced":true,"display_name":"Sender Type","dynamic":false,"info":"Type of sender.","name":"sender","options":["Machine","User"],"placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"str","value":"User"},"sender_name":{"advanced":true,"display_name":"Sender Name","dynamic":false,"info":"Name of the sender.","input_types":["Message"],"list":false,"load_from_db":false,"name":"sender_name","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"User"},"session_id":{"advanced":true,"display_name":"Session ID","dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","input_types":["Message"],"list":false,"load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"should_store_message":{"_input_type":"BoolInput","advanced":true,"display_name":"Store Messages","dynamic":false,"info":"Store the message in the history.","list":false,"name":"should_store_message","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"bool","value":true}},"lf_version":"1.0.18"},"type":"ChatInput"},"selected":false,"width":384,"height":302},{"id":"Memory-mf9Rj","type":"genericNode","position":{"x":5999.091723718988,"y":945.6090942047153},"data":{"type":"Memory","node":{"template":{"_type":"Component","memory":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"memory","value":"","display_name":"External Memory","advanced":false,"input_types":["BaseChatMessageHistory"],"dynamic":false,"info":"Retrieve messages from an external memory. If empty, it will use the Langflow tables.","title_case":false,"type":"other","_input_type":"HandleInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain.memory import ConversationBufferMemory\n\nfrom langflow.custom import Component\nfrom langflow.field_typing import BaseChatMemory\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs import HandleInput\nfrom langflow.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import LCBuiltinChatMemory, get_messages\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"n_messages":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"n_messages","value":100,"display_name":"Number of Messages","advanced":true,"dynamic":false,"info":"Number of messages to retrieve.","title_case":false,"type":"int","_input_type":"IntInput"},"order":{"trace_as_metadata":true,"options":["Ascending","Descending"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"order","value":"Ascending","display_name":"Order","advanced":true,"dynamic":false,"info":"Order of the messages.","title_case":false,"type":"str","_input_type":"DropdownInput"},"sender":{"trace_as_metadata":true,"options":["Machine","User","Machine and User"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"sender","value":"Machine and User","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Filter by sender type.","title_case":false,"type":"str","_input_type":"DropdownInput"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sender_name","value":"","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Filter by sender name.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"session_id","value":"","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"{sender_name}: {text}","display_name":"Template","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Retrieves stored chat messages from Langflow tables or an external memory.","icon":"message-square-more","base_classes":["BaseChatMemory","Data","Message"],"display_name":"Chat Memory","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"messages","display_name":"Messages (Data)","method":"retrieve_messages","value":"__UNDEFINED__","cache":true},{"types":["Message"],"selected":"Message","name":"messages_text","display_name":"Messages (Text)","method":"retrieve_messages_as_text","value":"__UNDEFINED__","cache":true},{"types":["BaseChatMemory"],"selected":"BaseChatMemory","name":"lc_memory","display_name":"Memory","method":"build_lc_memory","value":"__UNDEFINED__","cache":true}],"field_order":["memory","sender","sender_name","n_messages","session_id","order","template"],"beta":false,"edited":false,"lf_version":"1.0.18"},"id":"Memory-mf9Rj"},"selected":false,"width":384,"height":382},{"id":"AstraDB-TYZWg","type":"genericNode","position":{"x":2166.8363635428123,"y":117.66780977471853},"data":{"type":"AstraDB","node":{"template":{"_type":"Component","embedding":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"embedding","value":"","display_name":"Embedding or Astra Vectorize","advanced":false,"input_types":["Embeddings","dict"],"dynamic":false,"info":"Allows either an embedding model or an Astra Vectorize configuration.","title_case":false,"type":"other","_input_type":"HandleInput"},"ingest_data":{"trace_as_metadata":true,"list":true,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"ingest_data","value":"","display_name":"Ingest Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput"},"api_endpoint":{"load_from_db":true,"required":true,"placeholder":"","show":true,"name":"api_endpoint","value":"","display_name":"API Endpoint","advanced":false,"input_types":["Message"],"dynamic":false,"info":"API endpoint URL for the Astra DB service.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"batch_size":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"batch_size","value":"","display_name":"Batch Size","advanced":true,"dynamic":false,"info":"Optional number of data to process in a single batch.","title_case":false,"type":"int","_input_type":"IntInput"},"bulk_delete_concurrency":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"bulk_delete_concurrency","value":"","display_name":"Bulk Delete Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk delete operations.","title_case":false,"type":"int","_input_type":"IntInput"},"bulk_insert_batch_concurrency":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"bulk_insert_batch_concurrency","value":"","display_name":"Bulk Insert Batch Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations.","title_case":false,"type":"int","_input_type":"IntInput"},"bulk_insert_overwrite_concurrency":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"bulk_insert_overwrite_concurrency","value":"","display_name":"Bulk Insert Overwrite Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations that overwrite existing data.","title_case":false,"type":"int","_input_type":"IntInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from loguru import logger\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers import docs_to_data\nfrom langflow.inputs import DictInput, FloatInput\nfrom langflow.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\n\n\nclass AstraVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Implementation of Vector Store using Astra DB with search capabilities\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/vectorstores/astradb\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"search_input\",\n            display_name=\"Search Input\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding or Astra Vectorize\",\n            input_types=[\"Embeddings\", \"dict\"],\n            info=\"Allows either an embedding model or an Astra Vectorize configuration.\",  # TODO: This should be optional, but need to refactor langchain-astradb first.\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info=\"Optional dictionary defining the indexing policy for the collection.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError:\n            raise ImportError(\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid setup mode: {self.setup_mode}\")\n\n        if not isinstance(self.embedding, dict):\n            embedding_dict = {\"embedding\": self.embedding}\n        else:\n            from astrapy.info import CollectionVectorServiceOptions\n\n            dict_options = self.embedding.get(\"collection_vector_service_options\", {})\n            dict_options[\"authentication\"] = {\n                k: v for k, v in dict_options.get(\"authentication\", {}).items() if k and v\n            }\n            dict_options[\"parameters\"] = {k: v for k, v in dict_options.get(\"parameters\", {}).items() if k and v}\n            embedding_dict = {\n                \"collection_vector_service_options\": CollectionVectorServiceOptions.from_dict(dict_options)\n            }\n            collection_embedding_api_key = self.embedding.get(\"collection_embedding_api_key\")\n            if collection_embedding_api_key:\n                embedding_dict[\"collection_embedding_api_key\"] = collection_embedding_api_key\n\n        vector_store_kwargs = {\n            **embedding_dict,\n            \"collection_name\": self.collection_name,\n            \"token\": self.token,\n            \"api_endpoint\": self.api_endpoint,\n            \"namespace\": self.namespace or None,\n            \"metric\": self.metric or None,\n            \"batch_size\": self.batch_size or None,\n            \"bulk_insert_batch_concurrency\": self.bulk_insert_batch_concurrency or None,\n            \"bulk_insert_overwrite_concurrency\": self.bulk_insert_overwrite_concurrency or None,\n            \"bulk_delete_concurrency\": self.bulk_delete_concurrency or None,\n            \"setup_mode\": setup_mode_value,\n            \"pre_delete_collection\": self.pre_delete_collection or False,\n        }\n\n        if self.metadata_indexing_include:\n            vector_store_kwargs[\"metadata_indexing_include\"] = self.metadata_indexing_include\n        elif self.metadata_indexing_exclude:\n            vector_store_kwargs[\"metadata_indexing_exclude\"] = self.metadata_indexing_exclude\n        elif self.collection_indexing_policy:\n            vector_store_kwargs[\"collection_indexing_policy\"] = self.collection_indexing_policy\n\n        try:\n            vector_store = AstraDBVectorStore(**vector_store_kwargs)\n        except Exception as e:\n            raise ValueError(f\"Error initializing AstraDBVectorStore: {str(e)}\") from e\n\n        self._add_documents_to_vector_store(vector_store)\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store):\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                raise ValueError(f\"Error adding documents to AstraDBVectorStore: {str(e)}\") from e\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self):\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        elif self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        else:\n            return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        logger.debug(f\"Search input: {self.search_input}\")\n        logger.debug(f\"Search type: {self.search_type}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_input and isinstance(self.search_input, str) and self.search_input.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_input, search_type=search_type, **search_args)\n            except Exception as e:\n                raise ValueError(f\"Error performing search in AstraDBVectorStore: {str(e)}\") from e\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            self.status = data\n            return data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_indexing_policy":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"collection_indexing_policy","value":"","display_name":"Collection Indexing Policy","advanced":true,"dynamic":false,"info":"Optional dictionary defining the indexing policy for the collection.","title_case":false,"type":"str","_input_type":"StrInput"},"collection_name":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"collection_name","value":"questions","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","title_case":false,"type":"str","_input_type":"StrInput"},"metadata_indexing_exclude":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"metadata_indexing_exclude","value":"","display_name":"Metadata Indexing Exclude","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to exclude from the indexing.","title_case":false,"type":"str","_input_type":"StrInput"},"metadata_indexing_include":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"metadata_indexing_include","value":"","display_name":"Metadata Indexing Include","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to include in the indexing.","title_case":false,"type":"str","_input_type":"StrInput"},"metric":{"trace_as_metadata":true,"options":["cosine","dot_product","euclidean"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"metric","value":"","display_name":"Metric","advanced":true,"dynamic":false,"info":"Optional distance metric for vector comparisons in the vector store.","title_case":false,"type":"str","_input_type":"DropdownInput"},"namespace":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"namespace","value":"default_namespace","display_name":"Namespace","advanced":false,"dynamic":false,"info":"Optional namespace within Astra DB to use for the collection.","title_case":false,"type":"str","_input_type":"StrInput"},"number_of_results":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"number_of_results","value":4,"display_name":"Number of Results","advanced":false,"dynamic":false,"info":"Number of results to return.","title_case":false,"type":"int","_input_type":"IntInput"},"pre_delete_collection":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"pre_delete_collection","value":false,"display_name":"Pre Delete Collection","advanced":true,"dynamic":false,"info":"Boolean flag to determine whether to delete the collection before creating a new one.","title_case":false,"type":"bool","_input_type":"BoolInput"},"search_filter":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"name":"search_filter","value":{},"display_name":"Search Metadata Filter","advanced":true,"dynamic":false,"info":"Optional dictionary of filters to apply to the search query.","title_case":false,"type":"dict","_input_type":"DictInput"},"search_input":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"search_input","value":"","display_name":"Search Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MultilineInput"},"search_score_threshold":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"search_score_threshold","value":0,"display_name":"Search Score Threshold","advanced":true,"dynamic":false,"info":"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')","title_case":false,"type":"float","_input_type":"FloatInput"},"search_type":{"trace_as_metadata":true,"options":["Similarity","Similarity with score threshold","MMR (Max Marginal Relevance)"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"search_type","value":"Similarity","display_name":"Search Type","advanced":true,"dynamic":false,"info":"Search type to use","title_case":false,"type":"str","_input_type":"DropdownInput"},"setup_mode":{"trace_as_metadata":true,"options":["Sync","Async","Off"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"setup_mode","value":"Sync","display_name":"Setup Mode","advanced":true,"dynamic":false,"info":"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.","title_case":false,"type":"str","_input_type":"DropdownInput"},"token":{"load_from_db":true,"required":true,"placeholder":"","show":true,"name":"token","value":"","display_name":"Astra DB Application Token","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Authentication token for accessing Astra DB.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"}},"description":"Implementation of Vector Store using Astra DB with search capabilities","icon":"AstraDB","base_classes":["Data","Retriever","VectorStore"],"display_name":"Astra DB","documentation":"https://python.langchain.com/docs/integrations/vectorstores/astradb","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Retriever"],"selected":"Retriever","name":"base_retriever","display_name":"Retriever","method":"build_base_retriever","value":"__UNDEFINED__","cache":true},{"types":["Data"],"selected":"Data","name":"search_results","display_name":"Search Results","method":"search_documents","value":"__UNDEFINED__","cache":true},{"types":["VectorStore"],"selected":"VectorStore","name":"vector_store","display_name":"Vector Store","method":"cast_vector_store","value":"__UNDEFINED__","cache":true}],"field_order":["collection_name","token","api_endpoint","search_input","ingest_data","namespace","metric","batch_size","bulk_insert_batch_concurrency","bulk_insert_overwrite_concurrency","bulk_delete_concurrency","setup_mode","pre_delete_collection","metadata_indexing_include","embedding","metadata_indexing_exclude","collection_indexing_policy","number_of_results","search_type","search_score_threshold","search_filter"],"beta":false,"edited":false,"lf_version":"1.0.18"},"id":"AstraDB-TYZWg"},"selected":false,"width":384,"height":946,"dragging":false},{"id":"CustomComponent-Sz0Qi","type":"genericNode","position":{"x":585.9789878689377,"y":602.5460798664799},"data":{"type":"CustomComponent","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom loguru import logger\n\nclass CustomComponent(Component):\n    display_name = \"JSON Parser\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input Value\", value='{\"user_id\":\"8888888888\", \"user_question\": \"What are my miles?\"}'),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\")\n    ]\n\n    \n    def build_output(self) -> Data:\n        input_dict = json.loads(self.input_value)\n        \n        #test = '{\"user_id\":\"8888888888\", \"input\": \"What are my miles?\"}'\n        #input_dict = json.loads(test)\n        # Validate and create the Data object using the dictionary\n        #input_dict = {'user_id':'8888888888', 'input': 'What are my miles?'}\n        \n        data = Data(**input_dict)\n        \n        # Set the status to the created Data object\n        self.status = data\n        \n        # Return the Data object\n        return data","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input Value","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Use as a template to create your own component.","icon":"custom_components","base_classes":["Data"],"display_name":"Custom Component","documentation":"http://docs.langflow.org/components/custom","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output","display_name":"Output","method":"build_output","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"edited":true,"lf_version":"1.0.18"},"id":"CustomComponent-Sz0Qi"},"selected":false,"width":384,"height":330},{"id":"ParseData-GPBs1","type":"genericNode","position":{"x":1245.8197934618202,"y":54.6953125},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sep","value":"\n","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"{user_question}","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false,"lf_version":"1.0.18"},"id":"ParseData-GPBs1"},"selected":false,"width":384,"height":378},{"id":"OpenAIEmbeddings-pty3P","type":"genericNode","position":{"x":1460.2892119524404,"y":591.7496903235017},"data":{"type":"OpenAIEmbeddings","node":{"template":{"_type":"Component","chunk_size":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"chunk_size","value":1000,"display_name":"Chunk Size","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int","_input_type":"IntInput"},"client":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"client","value":"","display_name":"Client","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_openai.embeddings.base import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        SecretStrInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            tiktoken_enabled=self.tiktoken_enable,\n            default_headers=self.default_headers,\n            default_query=self.default_query,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            deployment=self.deployment,\n            embedding_ctx_length=self.embedding_ctx_length,\n            max_retries=self.max_retries,\n            model=self.model,\n            model_kwargs=self.model_kwargs,\n            base_url=self.openai_api_base,\n            api_key=self.openai_api_key,\n            openai_api_type=self.openai_api_type,\n            api_version=self.openai_api_version,\n            organization=self.openai_organization,\n            openai_proxy=self.openai_proxy,\n            timeout=self.request_timeout or None,\n            show_progress_bar=self.show_progress_bar,\n            skip_empty=self.skip_empty,\n            tiktoken_model_name=self.tiktoken_model_name,\n            dimensions=self.dimensions or None,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"default_headers":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"default_headers","value":{},"display_name":"Default Headers","advanced":true,"dynamic":false,"info":"Default headers to use for the API request.","title_case":false,"type":"dict","_input_type":"DictInput"},"default_query":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"default_query","value":{},"display_name":"Default Query","advanced":true,"dynamic":false,"info":"Default query parameters to use for the API request.","title_case":false,"type":"dict","_input_type":"DictInput"},"deployment":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"deployment","value":"","display_name":"Deployment","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"dimensions":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"dimensions","value":"","display_name":"Dimensions","advanced":true,"dynamic":false,"info":"The number of dimensions the resulting output embeddings should have. Only supported by certain models.","title_case":false,"type":"int","_input_type":"IntInput"},"embedding_ctx_length":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"embedding_ctx_length","value":1536,"display_name":"Embedding Context Length","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int","_input_type":"IntInput"},"max_retries":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"max_retries","value":3,"display_name":"Max Retries","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int","_input_type":"IntInput"},"model":{"trace_as_metadata":true,"options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model","value":"text-embedding-3-large","display_name":"Model","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"DropdownInput"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"model_kwargs","value":{},"display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict","_input_type":"DictInput"},"openai_api_base":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"openai_api_base","value":"","display_name":"OpenAI API Base","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"openai_api_key":{"load_from_db":true,"required":false,"placeholder":"","show":true,"name":"openai_api_key","value":"","display_name":"OpenAI API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"openai_api_type":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"openai_api_type","value":"","display_name":"OpenAI API Type","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"openai_api_version":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"openai_api_version","value":"","display_name":"OpenAI API Version","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"openai_organization":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"openai_organization","value":"","display_name":"OpenAI Organization","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"openai_proxy":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"openai_proxy","value":"","display_name":"OpenAI Proxy","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"request_timeout":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"request_timeout","value":"","display_name":"Request Timeout","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"},"show_progress_bar":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"show_progress_bar","value":false,"display_name":"Show Progress Bar","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput"},"skip_empty":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"skip_empty","value":false,"display_name":"Skip Empty","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput"},"tiktoken_enable":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"tiktoken_enable","value":true,"display_name":"TikToken Enable","advanced":true,"dynamic":false,"info":"If False, you must have transformers installed.","title_case":false,"type":"bool","_input_type":"BoolInput"},"tiktoken_model_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"tiktoken_model_name","value":"","display_name":"TikToken Model Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Generate embeddings using OpenAI models.","icon":"OpenAI","base_classes":["Embeddings"],"display_name":"OpenAI Embeddings","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Embeddings"],"selected":"Embeddings","name":"embeddings","display_name":"Embeddings","method":"build_embeddings","value":"__UNDEFINED__","cache":true}],"field_order":["default_headers","default_query","chunk_size","client","deployment","embedding_ctx_length","max_retries","model","model_kwargs","openai_api_base","openai_api_key","openai_api_type","openai_api_version","openai_organization","openai_proxy","request_timeout","show_progress_bar","skip_empty","tiktoken_model_name","tiktoken_enable","dimensions"],"beta":false,"edited":false,"lf_version":"1.0.18"},"id":"OpenAIEmbeddings-pty3P"},"selected":false,"width":384,"height":388,"dragging":false},{"id":"AstraDB-B96xa","type":"genericNode","position":{"x":2658.4596968289816,"y":1243.577682837272},"data":{"type":"AstraDB","node":{"template":{"_type":"Component","rows":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":true,"placeholder":"","show":true,"name":"rows","value":"","display_name":"Vector search rows","advanced":false,"input_types":["Data"],"dynamic":false,"info":"Rows of vector search output.","title_case":false,"type":"other","_input_type":"DataInput"},"user_info":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":true,"placeholder":"","show":true,"name":"user_info","value":"","display_name":"Object with user_id, user message, etc.","advanced":false,"input_types":["Data"],"dynamic":false,"info":"Object with user_id, user message, etc.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.vectorstores import VectorStore\nfrom loguru import logger\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers import docs_to_data\nfrom langflow.io import (\n    DataInput,\n    SecretStrInput,\n    StrInput,\n    Output,\n)\nfrom langflow.schema import Data\nfrom cassandra.query import SimpleStatement\nfrom cassandra.query import dict_factory\n\nfrom langflow.custom import Component\n\nclass CustomComponent(Component):\n    display_name: str = \"Query question_instruction table\"\n    description: str = \"Implementation of question_instruction Table\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/vectorstores/astradb\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    _cached_vectorstore: VectorStore | None = None\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"database_id\",\n            display_name=\"Database ID\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_DATABASE_ID\",\n            required=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within Astra DB to use for the collection.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"key_column_name\",\n            display_name=\"Key Column Name\",\n            info=\"Name of the column in the collection that will be used as the key for the documents.\",\n            required=True,\n        ),\n        DataInput(\n            name=\"rows\",\n            display_name=\"Vector search rows\",\n            info=\"Rows of vector search output.\",\n            required=True,\n        ),\n        DataInput(\n            name=\"user_info\",\n            display_name=\"Object with user_id, user message, etc.\",\n            info=\"Object with user_id, user message, etc.\",\n            required=True\n        )\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"query_table\"),\n    ]\n\n    def _build_session(self):\n        logger.debug(f\"Starting component\")\n        if self._cached_vectorstore:\n            return self._cached_vectorstore\n\n        try:\n            import cassio\n            cassio.init(\n                database_id=self.database_id,\n                token=self.token,\n                keyspace=self.namespace or \"default_namespace\"\n            )\n            session = cassio.config.resolve_session()\n            session.row_factory = dict_factory\n            return session\n        except ImportError:\n            raise ImportError(\"Could not import cassio. Please install it with `pip install cassio`.\")\n        except Exception as e:\n            raise ValueError(f\"Error initializing AstraDBVectorStore: {str(e)}\") from e\n\n    async def query_table(self) -> list[Data]:\n        session = self._build_session()\n        data_list = []\n        \n        async def execute_query(row):\n            try:\n                ann_query = f\"\"\"SELECT * FROM {self.namespace}.{self.collection_name}\n                                WHERE {self.key_column_name} = {getattr(row, self.key_column_name)}\"\"\"\n                future = session.execute_async(ann_query)\n    \n                # Fetch the result in a non-blocking way\n                result = await asyncio.to_thread(future.result)\n                rows = result.all()\n                data_list.extend(rows)\n                logger.debug(json.dumps(rows, default=str, indent=4))\n            except Exception as e:\n                logger.error(f\"Error querying the database: {str(e)}\")\n    \n        # Gather all queries to run concurrently\n        tasks = [execute_query(row) for row in self.rows]\n        await asyncio.gather(*tasks)\n    \n        # Return the Data object\n        entire_object = Data(rows=data_list, user_id=self.user_info.user_id, user_question=self.user_info.user_question)\n        self.status = entire_object\n        return entire_object","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_name":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"collection_name","value":"question_instruction","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","title_case":false,"type":"str","_input_type":"StrInput"},"database_id":{"load_from_db":true,"required":true,"placeholder":"","show":true,"name":"database_id","value":"","display_name":"Database ID","advanced":false,"input_types":["Message"],"dynamic":false,"info":"API endpoint URL for the Astra DB service.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"key_column_name":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"key_column_name","value":"question_id","display_name":"Key Column Name","advanced":false,"dynamic":false,"info":"Name of the column in the collection that will be used as the key for the documents.","title_case":false,"type":"str","_input_type":"StrInput"},"namespace":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"namespace","value":"default_namespace","display_name":"Namespace","advanced":false,"dynamic":false,"info":"Optional namespace within Astra DB to use for the collection.","title_case":false,"type":"str","_input_type":"StrInput"},"token":{"load_from_db":true,"required":true,"placeholder":"","show":true,"name":"token","value":"","display_name":"Astra DB Application Token","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Authentication token for accessing Astra DB.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"}},"description":"Implementation of question_instruction Table","icon":"AstraDB","base_classes":["Data"],"display_name":"Custom Component","documentation":"https://python.langchain.com/docs/integrations/vectorstores/astradb","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output","display_name":"Output","method":"query_table","value":"__UNDEFINED__","cache":true}],"field_order":["collection_name","token","database_id","namespace","key_column_name","rows","user_info"],"beta":false,"edited":true,"lf_version":"1.0.18"},"id":"AstraDB-B96xa"},"selected":false,"width":384,"height":742,"dragging":false},{"id":"ParseData-Kbr1J","type":"genericNode","position":{"x":3248.383750690803,"y":1721.7473791475468},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to process.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\nfrom langflow.schema import Data\nfrom pydantic.json import pydantic_encoder\nimport json\nfrom collections import defaultdict\nimport json\nfrom datetime import datetime\nfrom typing import List\n\nclass ParseDataComponent(Component):\n    display_name = \"Query Deduplication\"\n    description = \"Deduplicate the queries by (system, query)\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to process.\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Data:\n        rows = self.data.data[\"rows\"]\n        print(\"Running parse_data component\")\n        #print(rows)\n        user_id = self.data.user_id\n        user_question = self.data.user_question\n        \n        deduplicated_queries = defaultdict(lambda: {\n            'instruction': set(), 'system': None, 'query': None\n        })\n        \n        # Process documents to deduplicate by 'query' (case-insensitive)\n        for row in rows:\n            compound_key = row['system'].lower() + \" -> \" + row['query'].lower()  # Convert query to lowercase for case-insensitive deduplication\n            #print(f\"row['system'].lower() is: {row['system'].lower()}\")\n            #print(f\"row['query'].lower() is: {row['query'].lower()}\")\n            # If no question set for this query, assign the first one encountered\n            if deduplicated_queries[compound_key]['query'] is None:\n                deduplicated_queries[compound_key]['query'] = row['query']\n            if deduplicated_queries[compound_key]['system'] is None:\n                deduplicated_queries[compound_key]['system'] = row['system']\n        \n            # Combine instructions (using a set to ensure uniqueness)\n            deduplicated_queries[compound_key]['instruction'].add(row['instruction'])  # Add to a set to avoid duplicates\n                \n        print(f\"deduplicated_queries is: {deduplicated_queries}\")\n        # Execute each query and assign the output to 'data'\n        for compound_key, instruction_info in deduplicated_queries.items():\n            # Execute the query and store the result in the 'data' property\n            print(f\"Compound key: {compound_key}\")\n            print(f\"instruction_info: {instruction_info}\")\n            #details['data'] = execute_query(query)\n        \n        # Format the final deduplicated output\n        final_docs = [\n            {\n                'system': instruction_info['system'],\n                'query': instruction_info['query'].replace(\"@user_id\", user_id),\n                'instruction': list(instruction_info['instruction']),  # Convert set back to list for output\n            }\n            for compound_key, instruction_info in deduplicated_queries.items()\n        ]\n        \n        new_obj = Data(user_id = user_id, user_question = user_question, rows=final_docs)\n        \n        #[{\"text_key\": \"text\", \"data\":, \"user_info\": {\"text_key\": \"text\", \"data\": {\"user_id\": \"8888888888\", \"input\": \"What is my mileage?\"}, \"default_value\": \"\"}}, \"default_value\": \"\"}]\n        \n        self.status = new_obj\n        return new_obj","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Deduplicate the queries by (system, query)","icon":"braces","base_classes":["Data"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output","display_name":"Output","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data"],"beta":false,"edited":true,"lf_version":"1.0.18"},"id":"ParseData-Kbr1J"},"selected":false,"width":384,"height":264},{"id":"CustomComponent-tNuWo","type":"genericNode","position":{"x":3934.7132711160875,"y":1577.8922437538859},"data":{"type":"CustomComponent","node":{"template":{"_type":"Component","instruction_data":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"instruction_data","value":"(user_info and deduplicated rows)","display_name":"Instruction Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom loguru import logger\n\nclass CustomComponent(Component):\n    display_name = \"Query Router\"\n    description = \"Router for sending queries to their appropriate drivers for execution.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        DataInput(name=\"instruction_data\", display_name=\"Instruction Data\", value='(user_info and deduplicated rows)'),\n    ]\n\n    outputs = [\n        Output(display_name=\"Oracle queries\", name=\"oracle_output\", method=\"oracle_output\"),\n        Output(display_name=\"Cassandra queries\", name=\"cassandra_output\", method=\"cassandra_output\"),\n        Output(display_name=\"Splunk queries\", name=\"splunk_output\", method=\"splunk_output\"),\n        Output(display_name=\"MySQL queries\", name=\"mysql_output\", method=\"mysql_output\"),\n    ]\n\n    \n    def oracle_output(self) -> Data:\n        print(\"Running query router\")\n        input_dict = self.instruction_data\n        \n        matching_rows = []\n        \n        for row in input_dict.rows:\n            if row[\"system\"] == \"oracle\":\n                matching_rows.append(row)\n        \n        if len(matching_rows) > 0: \n            \n            data = Data(user_id = self.instruction_data.user_id, user_question = self.instruction_data.user_question, rows=matching_rows)\n        \n            # Set the status to the created Data object\n            self.status = data\n            \n            # Return the Data object\n            return data\n        else:\n            #self.stop(\"oracle_output\")\n            return None\n    \n    def cassandra_output(self) -> Data:\n        input_dict = self.instruction_data\n        \n        matching_rows = []\n        \n        for row in input_dict.rows:\n            if row[\"system\"] == \"cassandra\":\n                matching_rows.append(row)\n        \n        if len(matching_rows) > 0: \n            \n            data = Data(user_id = self.instruction_data.user_id, user_question = self.instruction_data.user_question, rows=matching_rows)\n        \n            # Set the status to the created Data object\n            self.status = data\n            \n            # Return the Data object\n            return data\n        else:\n            #self.stop(\"cassandra_output\")\n            return None\n            \n    def splunk_output(self) -> Data:\n        input_dict = self.instruction_data\n        \n        matching_rows = []\n        \n        for row in input_dict.rows:\n            if row[\"system\"] == \"splunk\":\n                matching_rows.append(row)\n        \n        if len(matching_rows) > 0: \n            \n            data = Data(user_id = self.instruction_data.user_id, user_question = self.instruction_data.user_question, rows=matching_rows)\n        \n            # Set the status to the created Data object\n            self.status = data\n            \n            # Return the Data object\n            return data\n        else:\n            #self.stop(\"splunk_output\")\n            return None\n    \n    def mysql_output(self) -> Data:\n        input_dict = self.instruction_data\n        \n        matching_rows = []\n        \n        for row in input_dict.rows:\n            if row[\"system\"] == \"mysql\":\n                matching_rows.append(row)\n        \n        if len(matching_rows) > 0: \n            \n            data = Data(user_id = self.instruction_data.user_id, user_question = self.instruction_data.user_question, rows=matching_rows)\n        \n            # Set the status to the created Data object\n            self.status = data\n            \n            # Return the Data object\n            return data\n        else:\n            #self.stop(\"mysql_output\")\n            return None","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Router for sending queries to their appropriate drivers for execution.","icon":"custom_components","base_classes":["Data"],"display_name":"Custom Component","documentation":"http://docs.langflow.org/components/custom","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"oracle_output","display_name":"Oracle queries","method":"oracle_output","value":"__UNDEFINED__","cache":true},{"types":["Data"],"selected":"Data","name":"cassandra_output","display_name":"Cassandra queries","method":"cassandra_output","value":"__UNDEFINED__","cache":true},{"types":["Data"],"selected":"Data","name":"splunk_output","display_name":"Splunk queries","method":"splunk_output","value":"__UNDEFINED__","cache":true},{"types":["Data"],"selected":"Data","name":"mysql_output","display_name":"MySQL queries","method":"mysql_output","value":"__UNDEFINED__","cache":true}],"field_order":["instruction_data"],"beta":false,"edited":true,"lf_version":"1.0.18"},"id":"CustomComponent-tNuWo"},"selected":false,"width":384,"height":451,"dragging":false},{"id":"CustomComponent-Lb2HY","type":"genericNode","position":{"x":4613.881140449143,"y":1520.2791302447226},"data":{"type":"CustomComponent","node":{"template":{"_type":"Component","instruction_data":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"instruction_data","value":"(user_info and deduplicated rows)","display_name":"Instruction Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput"},"DB_ID":{"trace_as_metadata":true,"load_from_db":true,"list":false,"required":false,"placeholder":"","show":true,"name":"DB_ID","value":"ASTRA_DB_DATABASE_ID","display_name":"DB_ID","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"DB_TOKEN":{"trace_as_metadata":true,"load_from_db":true,"list":false,"required":false,"placeholder":"","show":true,"name":"DB_TOKEN","value":"ASTRA_DB_TOKEN","display_name":"DB_TOKEN","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom loguru import logger\nimport asyncio\nimport json\nfrom datetime import datetime\nfrom typing import List\nfrom cassandra.query import SimpleStatement, dict_factory\n\nclass CustomComponent(Component):\n    display_name = \"Execute Cassandra queries\"\n    description = \"Execute Cassandra queries\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        DataInput(name=\"instruction_data\", display_name=\"Instruction Data\", value='(user_info and deduplicated rows)'),\n        StrInput(name=\"DB_ID\", display_name=\"DB_ID\", value='Database ID'),\n        StrInput(name=\"DB_TOKEN\", display_name=\"DB_TOKEN\", value='Database token'),\n    ]\n\n    outputs = [\n        Output(display_name=\"Query output\", name=\"query_output\", method=\"query_output\")\n    ]\n    \n    async def query_output(self) -> Data:\n        print(\"Running Cassandra query execution component\")\n        import cassio\n        \n        namespace = \"default_namespace\"\n        \n        cassio.init(\n            database_id=self.DB_ID,\n            token=self.DB_TOKEN,\n            keyspace=namespace\n        )\n        session = cassio.config.resolve_session()\n        session.row_factory = dict_factory\n        session.default_fetch_size = None  # set this to None to avoid problems with encoding in some cases\n        \n        def json_serial(obj):\n            \"\"\"JSON serializer for objects not serializable by default json code\"\"\"\n            if isinstance(obj, datetime):\n                return obj.isoformat()\n            raise TypeError(f\"Type {type(obj)} not serializable\")\n        \n        # Async function to execute a query and return the result\n        async def execute_query(row):\n            query = row[\"query\"]\n            print(f\"running query: {query}\")\n            future = session.execute_async(query)  # Use execute_async to run non-blocking queries\n            result = await asyncio.to_thread(future.result)  # Fetch the result in a non-blocking way\n            query_output_rows: List[dict] = result.all()\n            json_data = json.dumps(query_output_rows, indent=4, default=json_serial)\n            row[\"data\"] = json_data\n            print(f\"query result: {json_data}\")\n            return row\n        \n        # Gather all queries to run concurrently\n        if self.instruction_data:\n            if self.instruction_data.rows:\n                tasks = [execute_query(row) for row in self.instruction_data.rows]\n                await asyncio.gather(*tasks)\n            \n                # Set the status to the created Data object\n                data = Data(user_id=self.instruction_data.user_id, user_question=self.instruction_data.user_question, rows=self.instruction_data.rows)\n                self.status = data\n            else:\n                return None\n        else:\n            return None\n        \n        session.shutdown()\n        # Return the Data object\n        return data","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Execute Cassandra queries","icon":"custom_components","base_classes":["Data"],"display_name":"Custom Component","documentation":"http://docs.langflow.org/components/custom","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"query_output","display_name":"Query output","method":"query_output","value":"__UNDEFINED__","cache":true}],"field_order":["instruction_data","DB_ID","DB_TOKEN"],"beta":false,"edited":true,"lf_version":"1.0.18"},"id":"CustomComponent-Lb2HY"},"selected":false,"width":384,"height":460,"dragging":false},{"id":"CustomComponent-YMsHE","type":"genericNode","position":{"x":5333.0451468614165,"y":1413.9291212296926},"data":{"type":"CustomComponent","node":{"template":{"_type":"Component","cassandra_rows":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"cassandra_rows","value":"Hello, World!","display_name":"Cassandra rows","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput","load_from_db":false},"mysql_rows":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"mysql_rows","value":"(insert rows)","display_name":"MySQL rows","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput"},"oracle_rows":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"oracle_rows","value":"Hello, World!","display_name":"Oracle rows","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput","load_from_db":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\n\nclass CustomComponent(Component):\n    display_name = \"Query output combiner\"\n    description = \"Combines output of querying that various databases and APIs\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        #DataInput(name=\"splunk_rows\", display_name=\"Splunk rows\", value=\"Hello, World!\"),\n        DataInput(name=\"cassandra_rows\", display_name=\"Cassandra rows\", value=\"(insert rows)\"),\n        DataInput(name=\"oracle_rows\", display_name=\"Oracle rows\", value=\"(insert rows)\"),\n        DataInput(name=\"mysql_rows\", display_name=\"MySQL rows\", value=\"(insert rows)\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Data:\n        print(\"Running query output combiner component\")\n        all_rows = [] \n        user_id = None\n        user_question = None\n\n        if self.cassandra_rows and self.cassandra_rows.rows:\n            print(f\"self.cassandra_rows.rows are: {self.cassandra_rows.rows}\")\n            print(type(self.cassandra_rows.rows))\n            for row in self.cassandra_rows.rows:\n                print(f\"row is: {row}\")\n                row_obj = {\"instruction\": row[\"instruction\"], \"data\": row[\"data\"]}\n                all_rows.append(row_obj)\n            user_id = self.cassandra_rows.user_id\n            user_question = self.cassandra_rows.user_question\n        \n        if self.mysql_rows and self.mysql_rows.rows:\n            print(f\"self.mysql_rows.rows are: {self.mysql_rows.rows}\")\n            for row in self.mysql_rows.rows:\n                row_obj = {\"instruction\": row[\"instruction\"], \"data\": row[\"data\"]}\n                all_rows.append(row_obj)\n            \n            user_id = self.mysql_rows.user_id\n            user_question = self.mysql_rows.user_question    \n            \n        # for row in self.oracle_rows.rows:\n        #     row_obj = {\"instruction\": row[\"instruction\"], \"data\": row[\"data\"]}\n        #     all_rows.append(row_obj)\n        # user_id = self.oracle_rows.user_id\n        # user_question = self.oracle_rows.user_question    \n        \n        # for row in self.splunk_rows.rows:\n        #     row_obj = {\"instruction\": row[\"instruction\"], \"data\": row[\"data\"]}\n        #     all_rows.append(row_obj)\n        # user_id = self.splunk_rows.user_id\n        # user_question = self.splunk_rows.user_question   \n            \n        \n        data = Data(user_id=user_id, user_question = user_question, rows = all_rows)\n        self.status = data\n        print(f\"combined result: {data.model_dump()}\")\n        return data\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Combines output of querying that various databases and APIs","icon":"custom_components","base_classes":["Data"],"display_name":"Custom Component","documentation":"http://docs.langflow.org/components/custom","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output","display_name":"Output","method":"build_output","value":"__UNDEFINED__","cache":true}],"field_order":["cassandra_rows","oracle_rows","mysql_rows"],"beta":false,"edited":true,"lf_version":"1.0.18"},"id":"CustomComponent-YMsHE"},"selected":false,"width":384,"height":460,"dragging":false},{"id":"Prompt-l7YlL","type":"genericNode","position":{"x":6551.53388830283,"y":1304.2974707176645},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"You're helping a customer support agent with a customer. Please answer the customer's question based ONLY on the provided data and instructions (for interpreting the data) below. Please use the instructions in the JSON below to interpret the data. If the data retrieved is NULL for a field expected to exist to answer the question, say the data doesn't exist for that question. Otherwise, if you don't know the answer based on the available information, just say you don't know. Also, don't answer questions you've already answered in the previous chat context. \n\nCustomer question - THIS is the question you need to answer:\n\n{user_question}\n\n\n\n\nData and instructions:\n\n{rows}\n\n\n\n\n\nPrevious chat context - don't answer these questions:\n\n\n{chat_history}","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt","_input_type":"PromptInput"},"rows":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"rows","display_name":"rows","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"user_question":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"user_question","display_name":"user_question","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"chat_history":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"chat_history","display_name":"chat_history","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["user_question","rows","chat_history"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-l7YlL"},"selected":false,"width":384,"height":588,"dragging":false},{"id":"ParseData-616KE","type":"genericNode","position":{"x":5947.067904803463,"y":1426.146344861806},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sep","value":"\n","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"{rows}","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false,"lf_version":"1.0.18"},"id":"ParseData-616KE"},"selected":false,"width":384,"height":378},{"id":"ParseData-nmbnH","type":"genericNode","position":{"x":5925.565162307437,"y":1884.8715181103362},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sep","value":"\n","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"{user_question}","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false,"lf_version":"1.0.18"},"id":"ParseData-nmbnH"},"selected":false,"width":384,"height":378},{"id":"OpenAIModel-fwMSu","type":"genericNode","position":{"x":7147.553870347014,"y":1256.2786315917615},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","api_key":{"load_from_db":true,"required":false,"placeholder":"","show":true,"name":"api_key","value":"","display_name":"OpenAI API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"json_mode","value":false,"display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool","_input_type":"BoolInput"},"max_tokens":{"trace_as_metadata":true,"range_spec":{"step_type":"float","min":0,"max":128000,"step":0.1},"list":false,"required":false,"placeholder":"","show":true,"name":"max_tokens","value":"","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int","_input_type":"IntInput"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"model_kwargs","value":{},"display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict","_input_type":"DictInput"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o-mini","gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model_name","value":"gpt-4o","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"DropdownInput"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"openai_api_base","value":"","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str","_input_type":"StrInput"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"name":"output_schema","value":{},"display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict","_input_type":"DictInput"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"seed","value":1,"display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int","_input_type":"IntInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.1,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","api_key","temperature","seed"],"beta":false,"edited":false,"lf_version":"1.0.18"},"id":"OpenAIModel-fwMSu"},"selected":true,"width":384,"height":605,"dragging":false},{"id":"ChatOutput-S4jn4","type":"genericNode","position":{"x":7718.220647057326,"y":1357.129225751774},"data":{"type":"ChatOutput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"data_template":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"data_template","value":"{text}","display_name":"Data Template","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as output.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"sender","value":"Machine","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str","_input_type":"DropdownInput"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sender_name","value":"AI","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"session_id","value":"","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"should_store_message":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"should_store_message","value":true,"display_name":"Store Messages","advanced":true,"dynamic":false,"info":"Store the message in the history.","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message"],"display_name":"Chat Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","should_store_message","sender","sender_name","session_id","data_template"],"beta":false,"edited":false,"lf_version":"1.0.18"},"id":"ChatOutput-S4jn4","description":"Display a chat message in the Playground.","display_name":"Chat Output"},"selected":false,"width":384,"height":302},{"id":"CustomComponent-xalJ6","type":"genericNode","position":{"x":4606.83410914931,"y":2031.3437351740058},"data":{"type":"CustomComponent","node":{"template":{"_type":"Component","instruction_data":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"instruction_data","value":"(user_info and deduplicated rows)","display_name":"Instruction Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput"},"DB_HOST":{"trace_as_metadata":true,"load_from_db":true,"list":false,"required":false,"placeholder":"","show":true,"name":"DB_HOST","value":"MYSQL_HOST","display_name":"DB_HOST","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"DB_NAME":{"trace_as_metadata":true,"load_from_db":true,"list":false,"required":false,"placeholder":"","show":true,"name":"DB_NAME","value":"MYSQL_DB","display_name":"DB_NAME","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"DB_PASSWORD":{"trace_as_metadata":true,"load_from_db":true,"list":false,"required":false,"placeholder":"","show":true,"name":"DB_PASSWORD","value":"MYSQL_PASSWORD","display_name":"DB_PASSWORD","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"DB_USER":{"trace_as_metadata":true,"load_from_db":true,"list":false,"required":false,"placeholder":"","show":true,"name":"DB_USER","value":"MYSQL_USER","display_name":"DB_USER","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import mysql.connector\nfrom langflow.custom import Component\nfrom langflow.io import DataInput, StrInput, Output\nfrom langflow.schema import Data\nfrom loguru import logger\nimport json\nfrom datetime import datetime, date\nfrom typing import List\nimport asyncio\n\nclass CustomComponent(Component):\n    display_name = \"Execute MySQL queries\"\n    description = \"Execute MySQL queries\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        DataInput(name=\"instruction_data\", display_name=\"Instruction Data\", value='(user_info and deduplicated rows)'),\n        StrInput(name=\"DB_HOST\", display_name=\"DB_HOST\", value='Database Host'),\n        StrInput(name=\"DB_USER\", display_name=\"DB_USER\", value='Database User'),\n        StrInput(name=\"DB_PASSWORD\", display_name=\"DB_PASSWORD\", value='Database Password'),\n        StrInput(name=\"DB_NAME\", display_name=\"DB_NAME\", value='Database Name'),\n    ]\n\n    outputs = [\n        Output(display_name=\"Query output\", name=\"query_output\", method=\"query_output\")\n    ]\n\n    async def query_output(self) -> Data:\n        print(\"Running mysql query execution component\")\n        def json_serial(obj):\n            \"\"\"JSON serializer for objects not serializable by default json code\"\"\"\n            if isinstance(obj, (datetime, date)): # This adds support for MySQL dates\n                return obj.isoformat()\n            raise TypeError(f\"Type {type(obj)} not serializable\")\n        \n        async def execute_query(row):\n            try:\n                import mysql\n                import mysql.connector\n                # Connect to the MySQL database\n                connection = mysql.connector.connect(\n                    host=self.DB_HOST,\n                    user=self.DB_USER,\n                    password=self.DB_PASSWORD,\n                    database=self.DB_NAME\n                )\n                cursor = connection.cursor(dictionary=True)\n\n                query = row[\"query\"]\n                # Execute the query in a separate thread to avoid blocking\n                await asyncio.to_thread(cursor.execute, query)\n                query_output_rows = await asyncio.to_thread(cursor.fetchall)\n                json_data = json.dumps(query_output_rows, indent=4, default=json_serial)\n                row[\"data\"] = json_data\n\n                # Close the cursor and connection\n                cursor.close()\n                connection.close()\n\n            except mysql.connector.Error as err:\n                logger.error(f\"Error: {err}\")\n                row[\"data\"] = None  # Handle query failure gracefully\n            return row\n\n        # Check if rows is None before proceeding\n        print(f\"In MYSQL component: self.instruction_data is: {self.instruction_data}\")\n        if self.instruction_data:\n            if self.instruction_data.rows:\n                # Gather all queries to run concurrently\n                tasks = [execute_query(row) for row in self.instruction_data.rows]\n                await asyncio.gather(*tasks)\n            \n                # Set the status to the created Data object\n                data = Data(user_id=self.instruction_data.user_id, user_question=self.instruction_data.user_question, rows=self.instruction_data.rows)\n                self.status = data\n            \n                return data\n            else:\n                return None\n        else:\n            return None","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Execute MySQL queries","icon":"custom_components","base_classes":["Data"],"display_name":"Custom Component","documentation":"http://docs.langflow.org/components/custom","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"query_output","display_name":"Query output","method":"query_output","value":"__UNDEFINED__","cache":true}],"field_order":["instruction_data","DB_HOST","DB_USER","DB_PASSWORD","DB_NAME"],"beta":false,"edited":true,"lf_version":"1.0.18"},"id":"CustomComponent-xalJ6"},"selected":false,"width":384,"height":632,"dragging":false,"positionAbsolute":{"x":4606.83410914931,"y":2031.3437351740058}}],"edges":[{"source":"ChatInput-qBbK8","target":"CustomComponent-Sz0Qi","sourceHandle":"{dataType:ChatInput,id:ChatInput-qBbK8,name:message,output_types:[Message]}","targetHandle":"{fieldName:input_value,id:CustomComponent-Sz0Qi,inputTypes:[Message],type:str}","id":"reactflow__edge-ChatInput-qBbK8{dataType:ChatInput,id:ChatInput-qBbK8,name:message,output_types:[Message]}-CustomComponent-Sz0Qi{fieldName:input_value,id:CustomComponent-Sz0Qi,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"CustomComponent-Sz0Qi","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ChatInput","id":"ChatInput-qBbK8","name":"message","output_types":["Message"]}},"selected":false,"className":""},{"source":"OpenAIEmbeddings-pty3P","target":"AstraDB-TYZWg","sourceHandle":"{dataType:OpenAIEmbeddings,id:OpenAIEmbeddings-pty3P,name:embeddings,output_types:[Embeddings]}","targetHandle":"{fieldName:embedding,id:AstraDB-TYZWg,inputTypes:[Embeddings,dict],type:other}","id":"reactflow__edge-OpenAIEmbeddings-pty3P{dataType:OpenAIEmbeddings,id:OpenAIEmbeddings-pty3P,name:embeddings,output_types:[Embeddings]}-AstraDB-TYZWg{fieldName:embedding,id:AstraDB-TYZWg,inputTypes:[Embeddings,dict],type:other}","data":{"targetHandle":{"fieldName":"embedding","id":"AstraDB-TYZWg","inputTypes":["Embeddings","dict"],"type":"other"},"sourceHandle":{"dataType":"OpenAIEmbeddings","id":"OpenAIEmbeddings-pty3P","name":"embeddings","output_types":["Embeddings"]}},"selected":false,"className":""},{"source":"ParseData-GPBs1","target":"AstraDB-TYZWg","sourceHandle":"{dataType:ParseData,id:ParseData-GPBs1,name:text,output_types:[Message]}","targetHandle":"{fieldName:search_input,id:AstraDB-TYZWg,inputTypes:[Message],type:str}","id":"reactflow__edge-ParseData-GPBs1{dataType:ParseData,id:ParseData-GPBs1,name:text,output_types:[Message]}-AstraDB-TYZWg{fieldName:search_input,id:AstraDB-TYZWg,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"search_input","id":"AstraDB-TYZWg","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-GPBs1","name":"text","output_types":["Message"]}},"selected":false,"className":""},{"source":"CustomComponent-Sz0Qi","target":"ParseData-GPBs1","sourceHandle":"{dataType:CustomComponent,id:CustomComponent-Sz0Qi,name:output,output_types:[Data]}","targetHandle":"{fieldName:data,id:ParseData-GPBs1,inputTypes:[Data],type:other}","id":"reactflow__edge-CustomComponent-Sz0Qi{dataType:CustomComponent,id:CustomComponent-Sz0Qi,name:output,output_types:[Data]}-ParseData-GPBs1{fieldName:data,id:ParseData-GPBs1,inputTypes:[Data],type:other}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-GPBs1","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"CustomComponent","id":"CustomComponent-Sz0Qi","name":"output","output_types":["Data"]}},"selected":false,"className":""},{"source":"CustomComponent-Sz0Qi","target":"AstraDB-B96xa","sourceHandle":"{dataType:CustomComponent,id:CustomComponent-Sz0Qi,name:output,output_types:[Data]}","targetHandle":"{fieldName:user_info,id:AstraDB-B96xa,inputTypes:[Data],type:other}","id":"reactflow__edge-CustomComponent-Sz0Qi{dataType:CustomComponent,id:CustomComponent-Sz0Qi,name:output,output_types:[Data]}-AstraDB-B96xa{fieldName:user_info,id:AstraDB-B96xa,inputTypes:[Data],type:other}","data":{"targetHandle":{"fieldName":"user_info","id":"AstraDB-B96xa","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"CustomComponent","id":"CustomComponent-Sz0Qi","name":"output","output_types":["Data"]}},"selected":false,"className":""},{"source":"AstraDB-B96xa","target":"ParseData-Kbr1J","sourceHandle":"{dataType:AstraDB,id:AstraDB-B96xa,name:output,output_types:[Data]}","targetHandle":"{fieldName:data,id:ParseData-Kbr1J,inputTypes:[Data],type:other}","id":"reactflow__edge-AstraDB-B96xa{dataType:AstraDB,id:AstraDB-B96xa,name:output,output_types:[Data]}-ParseData-Kbr1J{fieldName:data,id:ParseData-Kbr1J,inputTypes:[Data],type:other}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-Kbr1J","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"AstraDB","id":"AstraDB-B96xa","name":"output","output_types":["Data"]}},"selected":false,"className":""},{"source":"AstraDB-TYZWg","target":"AstraDB-B96xa","sourceHandle":"{dataType:AstraDB,id:AstraDB-TYZWg,name:search_results,output_types:[Data]}","targetHandle":"{fieldName:rows,id:AstraDB-B96xa,inputTypes:[Data],type:other}","id":"reactflow__edge-AstraDB-TYZWg{dataType:AstraDB,id:AstraDB-TYZWg,name:search_results,output_types:[Data]}-AstraDB-B96xa{fieldName:rows,id:AstraDB-B96xa,inputTypes:[Data],type:other}","data":{"targetHandle":{"fieldName":"rows","id":"AstraDB-B96xa","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"AstraDB","id":"AstraDB-TYZWg","name":"search_results","output_types":["Data"]}},"selected":false,"className":""},{"source":"CustomComponent-tNuWo","target":"CustomComponent-Lb2HY","sourceHandle":"{dataType:CustomComponent,id:CustomComponent-tNuWo,name:cassandra_output,output_types:[Data]}","targetHandle":"{fieldName:instruction_data,id:CustomComponent-Lb2HY,inputTypes:[Data],type:other}","id":"reactflow__edge-CustomComponent-tNuWo{dataType:CustomComponent,id:CustomComponent-tNuWo,name:cassandra_output,output_types:[Data]}-CustomComponent-Lb2HY{fieldName:instruction_data,id:CustomComponent-Lb2HY,inputTypes:[Data],type:other}","data":{"targetHandle":{"fieldName":"instruction_data","id":"CustomComponent-Lb2HY","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"CustomComponent","id":"CustomComponent-tNuWo","name":"cassandra_output","output_types":["Data"]}},"selected":false,"className":""},{"source":"CustomComponent-Lb2HY","target":"CustomComponent-YMsHE","sourceHandle":"{dataType:CustomComponent,id:CustomComponent-Lb2HY,name:query_output,output_types:[Data]}","targetHandle":"{fieldName:cassandra_rows,id:CustomComponent-YMsHE,inputTypes:[Data],type:other}","id":"reactflow__edge-CustomComponent-Lb2HY{dataType:CustomComponent,id:CustomComponent-Lb2HY,name:query_output,output_types:[Data]}-CustomComponent-YMsHE{fieldName:cassandra_rows,id:CustomComponent-YMsHE,inputTypes:[Data],type:other}","data":{"targetHandle":{"fieldName":"cassandra_rows","id":"CustomComponent-YMsHE","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"CustomComponent","id":"CustomComponent-Lb2HY","name":"query_output","output_types":["Data"]}},"selected":false,"className":""},{"source":"CustomComponent-YMsHE","target":"ParseData-616KE","sourceHandle":"{dataType:CustomComponent,id:CustomComponent-YMsHE,name:output,output_types:[Data]}","targetHandle":"{fieldName:data,id:ParseData-616KE,inputTypes:[Data],type:other}","id":"reactflow__edge-CustomComponent-YMsHE{dataType:CustomComponent,id:CustomComponent-YMsHE,name:output,output_types:[Data]}-ParseData-616KE{fieldName:data,id:ParseData-616KE,inputTypes:[Data],type:other}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-616KE","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"CustomComponent","id":"CustomComponent-YMsHE","name":"output","output_types":["Data"]}},"selected":false,"className":""},{"source":"ParseData-616KE","target":"Prompt-l7YlL","sourceHandle":"{dataType:ParseData,id:ParseData-616KE,name:text,output_types:[Message]}","targetHandle":"{fieldName:rows,id:Prompt-l7YlL,inputTypes:[Message,Text],type:str}","id":"reactflow__edge-ParseData-616KE{dataType:ParseData,id:ParseData-616KE,name:text,output_types:[Message]}-Prompt-l7YlL{fieldName:rows,id:Prompt-l7YlL,inputTypes:[Message,Text],type:str}","data":{"targetHandle":{"fieldName":"rows","id":"Prompt-l7YlL","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-616KE","name":"text","output_types":["Message"]}},"selected":false,"className":""},{"source":"CustomComponent-YMsHE","target":"ParseData-nmbnH","sourceHandle":"{dataType:CustomComponent,id:CustomComponent-YMsHE,name:output,output_types:[Data]}","targetHandle":"{fieldName:data,id:ParseData-nmbnH,inputTypes:[Data],type:other}","id":"reactflow__edge-CustomComponent-YMsHE{dataType:CustomComponent,id:CustomComponent-YMsHE,name:output,output_types:[Data]}-ParseData-nmbnH{fieldName:data,id:ParseData-nmbnH,inputTypes:[Data],type:other}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-nmbnH","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"CustomComponent","id":"CustomComponent-YMsHE","name":"output","output_types":["Data"]}},"selected":false,"className":""},{"source":"Prompt-l7YlL","target":"OpenAIModel-fwMSu","sourceHandle":"{dataType:Prompt,id:Prompt-l7YlL,name:prompt,output_types:[Message]}","targetHandle":"{fieldName:input_value,id:OpenAIModel-fwMSu,inputTypes:[Message],type:str}","id":"reactflow__edge-Prompt-l7YlL{dataType:Prompt,id:Prompt-l7YlL,name:prompt,output_types:[Message]}-OpenAIModel-fwMSu{fieldName:input_value,id:OpenAIModel-fwMSu,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-fwMSu","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-l7YlL","name":"prompt","output_types":["Message"]}},"selected":false,"className":""},{"source":"OpenAIModel-fwMSu","target":"ChatOutput-S4jn4","sourceHandle":"{dataType:OpenAIModel,id:OpenAIModel-fwMSu,name:text_output,output_types:[Message]}","targetHandle":"{fieldName:input_value,id:ChatOutput-S4jn4,inputTypes:[Message],type:str}","id":"reactflow__edge-OpenAIModel-fwMSu{dataType:OpenAIModel,id:OpenAIModel-fwMSu,name:text_output,output_types:[Message]}-ChatOutput-S4jn4{fieldName:input_value,id:ChatOutput-S4jn4,inputTypes:[Message],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-S4jn4","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-fwMSu","name":"text_output","output_types":["Message"]}},"selected":false,"className":""},{"source":"Memory-mf9Rj","target":"Prompt-l7YlL","sourceHandle":"{dataType:Memory,id:Memory-mf9Rj,name:messages_text,output_types:[Message]}","targetHandle":"{fieldName:chat_history,id:Prompt-l7YlL,inputTypes:[Message,Text],type:str}","id":"reactflow__edge-Memory-mf9Rj{dataType:Memory,id:Memory-mf9Rj,name:messages_text,output_types:[Message]}-Prompt-l7YlL{fieldName:chat_history,id:Prompt-l7YlL,inputTypes:[Message,Text],type:str}","data":{"targetHandle":{"fieldName":"chat_history","id":"Prompt-l7YlL","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"Memory","id":"Memory-mf9Rj","name":"messages_text","output_types":["Message"]}},"selected":false,"className":""},{"source":"CustomComponent-xalJ6","target":"CustomComponent-YMsHE","sourceHandle":"{dataType:CustomComponent,id:CustomComponent-xalJ6,name:query_output,output_types:[Data]}","targetHandle":"{fieldName:mysql_rows,id:CustomComponent-YMsHE,inputTypes:[Data],type:other}","id":"reactflow__edge-CustomComponent-xalJ6{dataType:CustomComponent,id:CustomComponent-xalJ6,name:query_output,output_types:[Data]}-CustomComponent-YMsHE{fieldName:mysql_rows,id:CustomComponent-YMsHE,inputTypes:[Data],type:other}","data":{"targetHandle":{"fieldName":"mysql_rows","id":"CustomComponent-YMsHE","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"CustomComponent","id":"CustomComponent-xalJ6","name":"query_output","output_types":["Data"]}},"selected":false,"className":""},{"source":"ParseData-Kbr1J","target":"CustomComponent-tNuWo","sourceHandle":"{dataType:ParseData,id:ParseData-Kbr1J,name:output,output_types:[Data]}","targetHandle":"{fieldName:instruction_data,id:CustomComponent-tNuWo,inputTypes:[Data],type:other}","id":"reactflow__edge-ParseData-Kbr1J{dataType:ParseData,id:ParseData-Kbr1J,name:output,output_types:[Data]}-CustomComponent-tNuWo{fieldName:instruction_data,id:CustomComponent-tNuWo,inputTypes:[Data],type:other}","data":{"targetHandle":{"fieldName":"instruction_data","id":"CustomComponent-tNuWo","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-Kbr1J","name":"output","output_types":["Data"]}},"selected":false,"className":""},{"source":"ParseData-nmbnH","sourceHandle":"{dataType:ParseData,id:ParseData-nmbnH,name:text,output_types:[Message]}","target":"Prompt-l7YlL","targetHandle":"{fieldName:user_question,id:Prompt-l7YlL,inputTypes:[Message,Text],type:str}","data":{"targetHandle":{"fieldName":"user_question","id":"Prompt-l7YlL","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-nmbnH","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-nmbnH{dataType:ParseData,id:ParseData-nmbnH,name:text,output_types:[Message]}-Prompt-l7YlL{fieldName:user_question,id:Prompt-l7YlL,inputTypes:[Message,Text],type:str}","className":""},{"source":"CustomComponent-tNuWo","sourceHandle":"{dataType:CustomComponent,id:CustomComponent-tNuWo,name:mysql_output,output_types:[Data]}","target":"CustomComponent-xalJ6","targetHandle":"{fieldName:instruction_data,id:CustomComponent-xalJ6,inputTypes:[Data],type:other}","data":{"targetHandle":{"fieldName":"instruction_data","id":"CustomComponent-xalJ6","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"CustomComponent","id":"CustomComponent-tNuWo","name":"mysql_output","output_types":["Data"]}},"id":"reactflow__edge-CustomComponent-tNuWo{dataType:CustomComponent,id:CustomComponent-tNuWo,name:mysql_output,output_types:[Data]}-CustomComponent-xalJ6{fieldName:instruction_data,id:CustomComponent-xalJ6,inputTypes:[Data],type:other}","className":""}],"viewport":{"x":-1027.2042048938124,"y":-62.289235051973094,"zoom":0.2646985526361483}},"description":"Your Hub for Text Generation.","name":"SIA_flow_v4.16","last_tested_version":"1.0.18","endpoint_name":"SIA_flow","is_component":false}